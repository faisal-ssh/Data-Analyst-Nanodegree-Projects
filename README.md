# Data-Analyst-Nanodegree-Projects
Use statistics to uncover insights, communicate critical findings, and create data-driven solutions with Python

## Project 1 - Explore Weather Trends
Analyze local and global temperature data and compare the temperature trends where you live to overall global temperature trends by extracting the data from the 
database, creating a line chart to compare your city’s temperatures with the global temperatures, and making observations about the similarities and differences between 
the world averages and your city’s averages, as well as overall trends.

[Go to Report](Project-1_Explore-Weather-Trends/Project-1_Report.png)

## Project 2 - Investigate a Dataset
Analyze a dataset and then communicate findings about it using Python libraries NumPy, pandas, and Matplotlib to make analysis easier.

[Go to Jupyter Notebook](Project-2_Investigate-a-Dataset/Project-2_Investigate_a_Dataset.ipynb)

## Project 3 - Analyze A/B Test Results
The company has developed a new web page in order to try and increase the number of users who "convert," meaning the number of users who decide to pay for the company's 
product. The goal is to help the company understand if they should implement this new page, keep the old page, or perhaps run the experiment longer to make their 
decision.

[Go to Jupyter Notebook](Project-3_Analyze-AB-Test-Results/Project-3_Analyze_ab_test_results_notebook.ipynb)

## Project 4 - Wrangle and Analyze Data
Real-world data rarely comes clean. Using Python and its libraries (pandas, NumPy, requests, tweepy, json), data will be gathered from a variety of sources and in a 
variety of formats, assessed in its quality and tidiness, then will be cleaned. The goal is to wrangle WeRateDogs Twitter data to create interesting and trustworthy
analyses and visualizations.<br><br>
**Tasks:**
1. **Gathering Data:** from the following sources: csv file downloaded locally, tsv file hosted on the server, and json file queried from Twitter API.
2. **Assessing Data:** visually and programmatically for quality and tidiness issues.
3. **Cleaning Data:** clean all of the issues documented while assessing using the define-code-test framework.
4. **Storing Data:** store the cleaned master DataFrame in a CSV file.

[Go to Jupyter Notebook (Wrangle)](Project-4_Wrangle-and-Analyze-Data/Project-4_Wrangle.ipynb)<br>
[Go to Jupyter Notebook (Insights)](Project-4_Wrangle-and-Analyze-Data/Project-4_Insights.ipynb)

## Project 5 - Communicate Data Findings
This project has two parts that demonstrate the importance and value of data visualization techniques in the data analysis process:
1. **Part I - Exploratory data visualization:** use Python visualization libraries to systematically explore a selected dataset, starting from plots of single 
variables and building up to plots of multiple variables.
2. **Part II - Explanatory data visualization:** produce a short presentation that illustrates interesting properties, trends, and relationships that you discovered in 
your selected dataset. The primary method of conveying your findings will be through transforming your exploratory visualizations from the first part into polished, 
explanatory visualizations.

[Go to Jupyter Notebook](Project-5_Communicate-Data-Findings/Project-5_Analyze_ab_test_results_notebook.ipynb)
